{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b21c56c",
   "metadata": {},
   "source": [
    "### Two tower model code learning from [this repo](https://github.com/gauravchak/two_tower_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e70ada4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22f3c606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5435ed9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7f0ee9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72595676",
   "metadata": {},
   "source": [
    "#### Basic two tower Took example from Copilot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d8f3431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  item_id  rating  timestamp\n",
      "0      196      242       3  881250949\n",
      "1      186      302       3  891717742\n",
      "2       22      377       1  878887116\n",
      "3      244       51       2  880606923\n",
      "4      166      346       1  886397596\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ratings = pd.read_csv(\n",
    "    \"https://files.grouplens.org/datasets/movielens/ml-100k/u.data\",\n",
    "    sep=\"\\t\",\n",
    "    names=[\"user_id\", \"item_id\", \"rating\", \"timestamp\"]\n",
    ")\n",
    "\n",
    "print(ratings.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "403c8928",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = ratings[ratings[\"rating\"] >= 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8609a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_pairs = positive[[\"user_id\", \"item_id\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21589531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_items = ratings[\"item_id\"].max() + 1\n",
    "\n",
    "def sample_negative(user_id, pos_item):\n",
    "    neg = np.random.randint(1, num_items)\n",
    "    while neg == pos_item:\n",
    "        neg = np.random.randint(1, num_items)\n",
    "    return neg\n",
    "\n",
    "neg_items = [sample_negative(u, i) for u, i in pos_pairs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e97eceaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = pos_pairs[:, 0]\n",
    "pos_item_ids = pos_pairs[:, 1]\n",
    "neg_item_ids = np.array(neg_items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ea3f2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class MovieLensDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, users, pos_items, neg_items):\n",
    "        self.users = torch.tensor(users, dtype=torch.long,device=device)\n",
    "        self.pos_items = torch.tensor(pos_items, dtype=torch.long,device=device)\n",
    "        self.neg_items = torch.tensor(neg_items, dtype=torch.long, device=device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"user\": self.users[idx],\n",
    "            \"pos_item\": self.pos_items[idx],\n",
    "            \"neg_item\": self.neg_items[idx],\n",
    "        }\n",
    "\n",
    "dataset = MovieLensDataset(user_ids, pos_item_ids, neg_item_ids)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=256, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d7ac63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 943\n",
      "1 1674\n",
      "1 1682\n"
     ]
    }
   ],
   "source": [
    "print(user_ids.min(), user_ids.max())\n",
    "print(pos_item_ids.min(), pos_item_ids.max())\n",
    "print(neg_item_ids.min(), neg_item_ids.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f49a5a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserTower(torch.nn.Module):\n",
    "    def __init__(self, num_users, embed_dim=64):\n",
    "        super().__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_users + 1, embed_dim,device=device)\n",
    "\n",
    "    def forward(self, user_ids):\n",
    "        return torch.nn.functional.normalize(self.embedding(user_ids), dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c27f2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemTower(torch.nn.Module):\n",
    "    def __init__(self, num_items, embed_dim=64):\n",
    "        super().__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_items + 1, embed_dim,device=device)\n",
    "\n",
    "    def forward(self, item_ids):\n",
    "        return torch.nn.functional.normalize(self.embedding(item_ids), dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "36c3fd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(u, v):\n",
    "    return (u * v).sum(dim=-1)  # Dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b37ed09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(user_emb, pos_emb, neg_emb, margin=0.2):\n",
    "    pos_score = similarity(user_emb, pos_emb)\n",
    "    neg_score = similarity(user_emb, neg_emb)\n",
    "    loss = torch.relu(margin + neg_score - pos_score)\n",
    "    return loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "802b752c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.2098\n",
      "Epoch 1, Loss: 0.1925\n",
      "Epoch 2, Loss: 0.1978\n",
      "Epoch 3, Loss: 0.2163\n",
      "Epoch 4, Loss: 0.2108\n"
     ]
    }
   ],
   "source": [
    "user_tower = UserTower(num_users=ratings[\"user_id\"].max())\n",
    "item_tower = ItemTower(num_items=ratings[\"item_id\"].max())\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    list(user_tower.parameters()) + list(item_tower.parameters()),\n",
    "    lr=1e-3\n",
    ")\n",
    "\n",
    "for epoch in range(5):\n",
    "    for batch in loader:\n",
    "        user = batch[\"user\"]\n",
    "        pos_item = batch[\"pos_item\"]\n",
    "        neg_item = batch[\"neg_item\"]\n",
    "\n",
    "        user_emb = user_tower(user)\n",
    "        pos_emb = item_tower(pos_item)\n",
    "        neg_emb = item_tower(neg_item)\n",
    "\n",
    "        loss = contrastive_loss(user_emb, pos_emb, neg_emb)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79acf01",
   "metadata": {},
   "source": [
    "#### Making Recommendations (Topâ€‘K Retrieval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5cb2bf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_items = torch.arange(1, num_items,device=device)\n",
    "item_embs = item_tower(all_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4268ccd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 10\n",
    "user_emb = user_tower(torch.tensor([user_id],device=device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "35bc4916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended item IDs: [252, 15, 1199, 863, 713, 1310, 351, 1574, 1088, 183]\n",
      "Scores: [0.4566866457462311, 0.38565975427627563, 0.38276970386505127, 0.38113704323768616, 0.36996063590049744, 0.3659084141254425, 0.35912391543388367, 0.3317814767360687, 0.32569026947021484, 0.32416480779647827]\n"
     ]
    }
   ],
   "source": [
    "scores = (user_emb * item_embs).sum(dim=-1)\n",
    "topk = torch.topk(scores, k=10)\n",
    "print(\"Recommended item IDs:\", topk.indices.tolist())\n",
    "print(\"Scores:\", topk.values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d89ee1",
   "metadata": {},
   "source": [
    "#### Basic Mips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "28579d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ade8ab0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineMIPSModule(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        corpus_size:int, \n",
    "        embedding_dim:int) -> None:\n",
    "        super(BaselineMIPSModule,self).__init__()\n",
    "        self.corpus_size = corpus_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        # Create Random Corpus\n",
    "        self.corpus = torch.randn(corpus_size, embedding_dim,device=device) # [C, DI]\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        query_embedding: torch.Tensor, # [B, DI],\n",
    "        num_items: int, # (NI)\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        mips_score, indices = torch.topk(\n",
    "            torch.matmul(query_embedding, self.corpus.T),\n",
    "            k=num_items,\n",
    "            dim=1\n",
    "        )\n",
    "        \n",
    "        expanded_indices = indices.unsqueeze(2)\n",
    "        embeddings = self.corpus[expanded_indices]\n",
    "        embeddings = embeddings.squeeze(2)\n",
    "        \n",
    "        return indices, mips_score, embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3fc505",
   "metadata": {},
   "source": [
    "#### Two Tower base retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "98454c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1fdddd",
   "metadata": {},
   "source": [
    "##### Define Arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "416720dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoTowerBaseRetrieval(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_items:int,\n",
    "        user_id_hash_size: int,\n",
    "        user_id_embedding_dim: int,\n",
    "        user_features_size: int,\n",
    "        item_id_hash_size: int,\n",
    "        item_id_embedding_dim: int,\n",
    "        item_features_size:int,\n",
    "        user_value_weights: List[float],\n",
    "        mips_module: BaselineMIPSModule,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.num_items = num_items\n",
    "        \n",
    "        self.user_value_weights = torch.Tensor(user_value_weights).to(device)\n",
    "        self.mips_module = mips_module\n",
    "        \n",
    "        # Create the machinery for user tower\n",
    "\n",
    "        # 1. Create a module to represent user preference by a table lookup.\n",
    "        # Please see https://github.com/gauravchak/user_preference_modeling\n",
    "        # for other ways to represent user preference embedding.\n",
    "        self.user_id_embedding_arch = nn.Embedding(\n",
    "            user_id_hash_size, user_id_embedding_dim,device=device\n",
    "            )\n",
    "        # 2. Create an arch to process the user_features. We are using one\n",
    "        # hidden layer of 256 dimensions. This is just a reasonable default.\n",
    "        # You can experiment with other architectures.\n",
    "        self.user_features_arch = nn.Sequential(\n",
    "            nn.Linear(user_features_size, 256,device=device),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, user_id_embedding_dim,device=device),\n",
    "        )\n",
    "        \n",
    "        # 3. Create an arch to process the user_tower_input\n",
    "        # Input dimension =\n",
    "        #   user_id_embedding_dim from get_user_embedding,\n",
    "        #      essentially based on user_id\n",
    "        #   + user_id_embedding_dim from user_features_arch,\n",
    "        #      essentially based on user_features\n",
    "        # Output dimension = item_id_embedding_dim\n",
    "        # The output of this arch will be used for MIPS module.\n",
    "        # Hence the output dimension needs to be same as the item tower output.\n",
    "        self.user_tower_arch = nn.Linear(\n",
    "            in_features=2 * user_id_embedding_dim,\n",
    "            out_features=item_id_embedding_dim,\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        # Create arch for item tower\n",
    "\n",
    "        # 1. Embedding layers for item id\n",
    "        self.item_id_embedding_arch = nn.Embedding(\n",
    "            item_id_hash_size,\n",
    "            item_id_embedding_dim,\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        # 2. Create an arch to process the item_features\n",
    "        self.item_featurs_arch = nn.Sequential(\n",
    "            nn.Linear(item_features_size, 256,device=device),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, item_id_embedding_dim,device=device),\n",
    "        )\n",
    "        \n",
    "        # 3. Create an arch to process the item_tower_input\n",
    "        self.item_tower_arch = nn.Linear(\n",
    "            in_features=2 * item_id_embedding_dim,\n",
    "            out_features=item_id_embedding_dim,\n",
    "            device=device\n",
    "        )\n",
    "    def get_user_embedding(\n",
    "        self,\n",
    "        user_id: torch.Tensor,\n",
    "        user_features: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        user_id_embedding = self.user_id_embedding_arch(user_id)\n",
    "        return user_id_embedding\n",
    "    \n",
    "    def process_user_features(\n",
    "        self,\n",
    "        user_id: torch.Tensor,\n",
    "        user_features: torch.Tensor,\n",
    "        user_history: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        user_id_emb = self.get_user_embedding(user_id, user_features) # [B, DU]\n",
    "        user_features_emb = self.user_features_arch(user_features) #[B, DU]\n",
    "        user_tower_input = torch.cat([user_id_emb, user_features_emb], dim=1) # [B, 2*DU]\n",
    "        return user_tower_input\n",
    "    \n",
    "    def compute_user_embedding(\n",
    "        self,\n",
    "        user_id: torch.Tensor,\n",
    "        user_features: torch.Tensor,\n",
    "        user_history: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        user_tower_input = self.process_user_features(\n",
    "            user_id, user_features, user_history\n",
    "        ) # [B, 2*DU]\n",
    "        # Compute user embedding\n",
    "        user_embedding = self.user_tower_arch(user_tower_input) # [B, DI]\n",
    "        return user_embedding\n",
    "    \n",
    "    def compute_item_embedding(\n",
    "        self,\n",
    "        item_id: torch.Tensor,\n",
    "        item_features: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        # Process item id\n",
    "        item_id_emb = self.item_id_embedding_arch(item_id) # [B, DI]\n",
    "        # Process item features\n",
    "        item_features_emb = self.item_featurs_arch(item_features) # [B, DI]\n",
    "        # Concatenate item id embedding and item features embedding\n",
    "        item_tower_input = torch.cat([item_id_emb, item_features_emb], dim=1) # [B, 2*DI]\n",
    "        # Compute item embedding\n",
    "        item_embedding = self.item_tower_arch(item_tower_input) # [B, DI]\n",
    "        return item_embedding\n",
    "    \n",
    "    def debias_net_user_value(\n",
    "        self, \n",
    "        net_user_value: torch.Tensor, # [B]\n",
    "        position: torch.Tensor, # [B]\n",
    "        user_embeddings: torch.Tensor, # [B, DI]\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "\n",
    "        return net_user_value, torch.zeros_like(net_user_value,device=device)\n",
    "    \n",
    "    def compute_training_loss(\n",
    "        self,\n",
    "        user_embeddings: torch.Tensor, #[B, DI ]\n",
    "        item_embeddings: torch.Tensor, #[B, DI ]\n",
    "        position: torch.Tensor, #[B, ]\n",
    "        labels: torch.Tensor, #[B, T]\n",
    "    ) -> torch.Tensor:\n",
    "        # Compute similarity scores\n",
    "        scores = torch.matmul(\n",
    "            user_embeddings, # [B, DU]\n",
    "            item_embeddings.T,  # [B, DI]\n",
    "        ) # [B, B]\n",
    "        \n",
    "        target = torch.arange(scores.shape[0]).to(scores.device) #[B, ]\n",
    "        loss = F.cross_entropy(scores, target, reduction='none') #[B, ]\n",
    "        \n",
    "        net_user_value = torch.sum(\n",
    "            labels * self.user_value_weights,\n",
    "            dim=-1 \n",
    "        ) #[B, ]\n",
    "        \n",
    "        # optional debiasing step\n",
    "        net_user_value, additional_loss = self.debias_net_user_value(\n",
    "            net_user_value=net_user_value,\n",
    "            position=position,\n",
    "            user_embeddings=user_embeddings,\n",
    "        ) #[B], [1]\n",
    "        \n",
    "        # Floor by epsilon to avoid zero division\n",
    "        net_user_value = torch.clamp(net_user_value, min=0.000001) #[B, ]\n",
    "        \n",
    "        # Normalize net user value by the max value in the batch\n",
    "        net_user_value = net_user_value / torch.max(net_user_value) #[B, ]\n",
    "        \n",
    "        # compute the product of loss and net user value\n",
    "        weighted_loss = loss * net_user_value #[B, ]\n",
    "        loss = torch.mean(weighted_loss) #[1]\n",
    "        return loss\n",
    "    \n",
    "    def train_forward(\n",
    "        self,\n",
    "        user_id: torch.Tensor, #[B]\n",
    "        user_features: torch.Tensor, #[B, IU]\n",
    "        user_history: torch.Tensor, #[B, H]\n",
    "        item_id: torch.Tensor, # [B]\n",
    "        item_features: torch.Tensor, #[B, II]\n",
    "        position: torch.Tensor, #[B]\n",
    "        labels: torch.Tensor, #[B, T]\n",
    "        ) -> float:\n",
    "        # compute user embeddings\n",
    "        user_embeddings = self.compute_user_embedding(\n",
    "            user_id, user_features, user_history\n",
    "        )\n",
    "        \n",
    "        # compute item embseddings\n",
    "        \n",
    "        item_embeddings = self.compute_item_embeddings(\n",
    "            item_id, item_features\n",
    "        ) # [B, DI]\n",
    "        \n",
    "        loss = self.compute_training_loss(\n",
    "            user_embeddings = user_embeddings,\n",
    "            item_embeddings = item_embeddings,\n",
    "            position = position,\n",
    "            labels = labels,\n",
    "        )\n",
    "        return loss\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        user_id: torch.Tensor,  # [B]\n",
    "        user_features: torch.Tensor,  # [B, IU]\n",
    "        user_history: torch.Tensor,  # [B, H]\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"This is used for inference.\n",
    "        Compute the user embedding and return the top num_items items using the mips module.\n",
    "        Args:\n",
    "            user_id (torch.Tensor): Tensor representing the user ID. Shape: [B]\n",
    "            user_features (torch.Tensor): Tensor representing the user features. Shape: [B, IU]\n",
    "            user_history (torch.Tensor): Tensor representing the user history. Shape: [B, H]\n",
    "        Returns:\n",
    "            torch.Tensor: Tensor representing the top num_items items. Shape: [B, num_items]\n",
    "        \"\"\"\n",
    "        # Compute the user embedding\n",
    "        user_embedding = self.compute_user_embedding(\n",
    "            user_id, user_features, user_history\n",
    "        )\n",
    "        # Query the mips module to get the top num_items items and their\n",
    "        # embeddings. The embeddings aren't strictly necessary in the base\n",
    "        # implementation.\n",
    "        top_items, _, _ = self.mips_module(\n",
    "            query_embedding=user_embedding, num_items=self.num_items\n",
    "        )  # indices [B, num_items], mips_scores [B, NI], embeddings [B, NI, DI]  # noqa\n",
    "        return top_items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a6ee57",
   "metadata": {},
   "source": [
    "##### Helper Fxn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6b13f07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_items = 10\n",
    "user_id_hash_size = 100\n",
    "user_id_embedding_dim = 50\n",
    "user_features_size = 20\n",
    "item_id_hash_size = 150\n",
    "item_id_embedding_dim = 40\n",
    "item_features_size = 30\n",
    "tasknum: int = 3\n",
    "user_value_weights = [0.1, 0.2, 0.3]  # dimension = tasknum\n",
    "user_history_seqlen: int = 128\n",
    "corpus_size: int = 1001\n",
    "mips_module = BaselineMIPSModule(\n",
    "    corpus_size=corpus_size,\n",
    "    embedding_dim=item_id_embedding_dim,\n",
    ")\n",
    "candidate_generator = TwoTowerBaseRetrieval(\n",
    "    num_items=num_items,\n",
    "    user_id_hash_size=user_id_hash_size,\n",
    "    user_id_embedding_dim=user_id_embedding_dim,\n",
    "    user_features_size=user_features_size,\n",
    "    item_id_hash_size=item_id_hash_size,\n",
    "    item_id_embedding_dim=item_id_embedding_dim,\n",
    "    item_features_size=item_features_size,\n",
    "    user_value_weights=user_value_weights,\n",
    "    mips_module=mips_module,\n",
    ")\n",
    "batch_size = 32\n",
    "user_id = torch.randint(\n",
    "    0, user_id_hash_size, (batch_size,),device=device\n",
    ")\n",
    "user_features = torch.randn(\n",
    "    batch_size, user_features_size,device=device\n",
    ")\n",
    "user_history = torch.randint(\n",
    "    low=0,\n",
    "    high=num_items,\n",
    "    size=(batch_size, user_history_seqlen),device=device\n",
    ")\n",
    "\n",
    "item_recommendations = candidate_generator(\n",
    "            user_id, user_features, user_history\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "544d5400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "print(item_recommendations.shape)\n",
    "print(torch.Size([batch_size, candidate_generator.num_items]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c53f0e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_sklearn_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
